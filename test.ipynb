{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ff847-892a-4e7d-aa55-0447885df900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7c0cb8-ceee-4106-8805-93f2055d1d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 192, 192, 192, 1)\n",
      "(None, 192, 192, 192, 1)\n",
      "(None, 192, 192, 192, 1)\n",
      "(None, 192, 192, 192, 1)\n",
      "(None, 192, 192, 192, 1)\n",
      "(None, 192, 192, 192, 1)\n",
      "models_synth_less_conc_norm_shapes_feta_192/weights_epoch_300.h5\n",
      "Loaded weights from the checkpoint and continued training.\n",
      "file: epiSurvey_25w1d_046_f07, Dice: 0.1421, Kevin: 0.0020, Ebner: 0.8013, Salehi: 0.0002\n",
      "file: epiSurvey_35w3d_025_f12, Dice: 0.0206, Kevin: 0.0000, Ebner: 0.4859, Salehi: 0.0594\n",
      "file: T2sEPI_012_26w5d_041_f19, Dice: 0.0833, Kevin: 0.0025, Ebner: 0.8765, Salehi: 0.0000\n",
      "file: epiSurvey_35w3d_026_f09, Dice: 0.0016, Kevin: 0.0000, Ebner: 0.1488, Salehi: 0.0004\n",
      "file: epiSurvey_23w1d_029_f09, Dice: 0.0332, Kevin: 0.0016, Ebner: 0.7256, Salehi: 0.0020\n",
      "file: epiSurvey_29w4d_044_f11, Dice: 0.2041, Kevin: 0.0041, Ebner: 0.0000, Salehi: 0.0045\n",
      "file: epiSurvey_35w4d_032_f05, Dice: 0.0273, Kevin: 0.0000, Ebner: 0.0000, Salehi: 0.0000\n",
      "file: epiSurvey_36w2d_023_f03, Dice: 0.1352, Kevin: 0.0001, Ebner: 0.5378, Salehi: 0.0023\n",
      "file: epiSurvey_24w6d_029_f19, Dice: 0.1994, Kevin: 0.0485, Ebner: 0.7316, Salehi: 0.0307\n",
      "file: T2sEPI_007_21w4d_046_f02, Dice: 0.1195, Kevin: 0.0000, Ebner: 0.5384, Salehi: 0.0000\n",
      "file: epiSurvey_38w1d_028_f04, Dice: 0.0698, Kevin: 0.0000, Ebner: 0.0000, Salehi: 0.0000\n",
      "file: T2sEPI_014_20w6d_043_f17, Dice: 0.0943, Kevin: 0.0000, Ebner: 0.7423, Salehi: 0.0000\n",
      "file: epiSurvey_35w0d_061_f12, Dice: 0.1125, Kevin: 0.0135, Ebner: 0.9068, Salehi: 0.0078\n",
      "file: epiSurvey_25w1d_045_f14, Dice: 0.1376, Kevin: 0.0000, Ebner: 0.7801, Salehi: 0.0000\n",
      "file: T2sEPI_022_35w5d_023_f12, Dice: 0.0649, Kevin: 0.0000, Ebner: 0.6814, Salehi: 0.0000\n",
      "file: T2sEPI_012_26w5d_042_f14, Dice: 0.1172, Kevin: 0.0003, Ebner: 0.8554, Salehi: 0.0000\n",
      "file: epiSurvey_35w0d_059_f10, Dice: 0.3116, Kevin: 0.0000, Ebner: 0.9223, Salehi: 0.0195\n",
      "file: epiSurvey_24w6d_037_f18, Dice: 0.1511, Kevin: 0.0260, Ebner: 0.8375, Salehi: 0.0517\n",
      "file: epiSurvey_37w2d_032_f10, Dice: 0.0192, Kevin: 0.0000, Ebner: 0.0000, Salehi: 0.0000\n",
      "file: epiSurvey_29w4d_043_f14, Dice: 0.2048, Kevin: 0.0000, Ebner: 0.8790, Salehi: 0.0066\n",
      "file: epiSurvey_36w2d_022_f06, Dice: 0.1588, Kevin: 0.0000, Ebner: 0.4312, Salehi: 0.0000\n",
      "file: epiSurvey_35w4d_034_f08, Dice: 0.0563, Kevin: 0.0002, Ebner: 0.7980, Salehi: 0.0000\n",
      "file: T2sEPI_004_33w1d_056_f05, Dice: 0.1495, Kevin: 0.0032, Ebner: 0.8768, Salehi: 0.0000\n",
      "file: T2sEPI_007_21w4d_041_f04, Dice: 0.0562, Kevin: 0.0000, Ebner: 0.2293, Salehi: 0.0000\n",
      "file: epiSurvey_26w5d_029_f13, Dice: 0.1334, Kevin: 0.0000, Ebner: 0.6147, Salehi: 0.0000\n",
      "file: epiSurvey_24w2d_029_f14, Dice: 0.1032, Kevin: 0.0000, Ebner: 0.6900, Salehi: 0.0001\n",
      "file: T2sEPI_020_21w1d_035_f15, Dice: 0.0462, Kevin: 0.0671, Ebner: 0.3384, Salehi: 0.0000\n",
      "file: epiSurvey_35w3d_024_f11, Dice: 0.0068, Kevin: 0.0000, Ebner: 0.3764, Salehi: 0.0007\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'b2_salehi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 449\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Example data with one mean and one std for each baseline\u001b[39;00m\n\u001b[1;32m    448\u001b[0m second_trimester_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalehi\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mb2_salehi\u001b[49m,\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeraudren\u001b[39m\u001b[38;5;124m'\u001b[39m: b2_kevin,\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEbner\u001b[39m\u001b[38;5;124m'\u001b[39m: b2_ebner,\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf-Strip\u001b[39m\u001b[38;5;124m'\u001b[39m: b2_fstrip\n\u001b[1;32m    453\u001b[0m }\n\u001b[1;32m    455\u001b[0m third_trimester_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalehi\u001b[39m\u001b[38;5;124m'\u001b[39m: b3_salehi,\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeraudren\u001b[39m\u001b[38;5;124m'\u001b[39m: b3_kevin,\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEbner\u001b[39m\u001b[38;5;124m'\u001b[39m: b3_ebner,\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf-Strip\u001b[39m\u001b[38;5;124m'\u001b[39m: b3_fstrip\n\u001b[1;32m    460\u001b[0m }\n\u001b[1;32m    462\u001b[0m epi_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalehi\u001b[39m\u001b[38;5;124m'\u001b[39m: epi_salehi,\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeraudren\u001b[39m\u001b[38;5;124m'\u001b[39m: epi_kevin,\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEbner\u001b[39m\u001b[38;5;124m'\u001b[39m: epi_ebner,\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf-Strip\u001b[39m\u001b[38;5;124m'\u001b[39m: epi_fstrip\n\u001b[1;32m    467\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b2_salehi' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from neurite.tf import models  # Assuming the module's location\n",
    "import voxelmorph.tf.losses as vtml\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Input, BatchNormalization\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import neurite as ne\n",
    "import sys\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.models import load_model\n",
    "from neurite_sandbox.tf.models import labels_to_labels\n",
    "import nibabel as nib\n",
    "import tqdm\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import neurite as ne\n",
    "import voxelmorph as vxm\n",
    "from utils import *\n",
    "import pathlib\n",
    "import surfa as sf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import surfa as sf\n",
    "from utils import resize\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def process_image(im, unet_model):\n",
    "    a = im.copy()\n",
    "    return unet_model.predict(a[None,...,None], verbose=0)\n",
    "    \n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2.0 * intersection) / (union) \n",
    "\n",
    "def dynamic_resize(image, target_width=192):   \n",
    "\n",
    "    fov = np.multiply(image.shape, image.geom.voxsize)\n",
    "\n",
    "    new_voxsize = fov / target_width\n",
    "\n",
    "    new_voxsize = np.max(new_voxsize[:2])  # ignore slice thickness\n",
    "    return new_voxsize\n",
    "    \n",
    "def my_hard_dice(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    dice = dice_coefficient(y_true_flat, y_pred_flat)\n",
    "    return dice\n",
    "from skimage.measure import label   \n",
    "\n",
    "def getLargestCC(segmentation):\n",
    "    labels = label(segmentation)\n",
    "    assert( labels.max() != 0 ) # assume at least 1 CC\n",
    "    largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1\n",
    "    return largestCC\n",
    "    \n",
    "def soft_dice(a, b):\n",
    "    dim = len(a.shape) - 2\n",
    "    space = list(range(1, dim + 1))\n",
    "    # print(\"dim\",dim,\"space\",space,\"a.dim\",a.shape,\"b.dim\",b.shape)\n",
    "    top = 2 * tf.reduce_sum(a * b, axis=space)\n",
    "    bot = tf.reduce_sum(a ** 2, axis=space) + tf.reduce_sum(b ** 2, axis=space)\n",
    "    \n",
    "    out = tf.divide(top, bot + 1e-6)\n",
    "    return -tf.reduce_mean(out)\n",
    "\n",
    "def my_dice_coefficient(y_true, y_pred, smooth=1e-8):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2.0 * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "def minmax_norm(x):\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "def find_manual_mask(filename):\n",
    "    base_filename, _ = os.path.splitext(filename)  # Separate filename and extension\n",
    "    pattern = re.compile(rf\"manual_masks_b\\d+_mom_\\d+_{re.escape(base_filename)}_segment\\.nii\\.gz\")\n",
    "\n",
    "    matches = [f for f in os.listdir(\"mgh_2d\") if pattern.match(f)]\n",
    "    \n",
    "    if matches:\n",
    "        return matches[0]\n",
    "\n",
    "def percentile_norm(x, percentile=90):\n",
    "    p_value = np.percentile(x, percentile)\n",
    "    \n",
    "    x_clipped = np.clip(x, 0, p_value)\n",
    "    \n",
    "    x_min_clipped = np.min(x_clipped)\n",
    "    x_max_clipped = np.max(x_clipped)\n",
    "    normalized_x = (x_clipped - x_min_clipped) / (x_max_clipped - x_min_clipped)\n",
    "    return normalized_x\n",
    "    \n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "warp_blur_min=np.array([2, 4, 8])\n",
    "bias_blur_min=np.array([2, 4, 8])\n",
    "bias_blur_max=bias_blur_min*2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.seed(3000)\n",
    "\n",
    "def load_model3D(checkpoint_path,gmm, norm, num_dim=3,nb_labels=2,\n",
    "                                            dimx=192,\n",
    "                                            dimy=192,\n",
    "                                            dimz=192,\n",
    "                                            batch_size=8,\n",
    "                                            warp_max=2.5,\n",
    "                                            warp_min=.5,\n",
    "                                            warp_blur_min=np.array([2, 4, 8]),\n",
    "                                            warp_blur_max=warp_blur_min*2,\n",
    "                                            bias_blur_min=np.array([2, 4, 8]),\n",
    "                                            bias_blur_max=bias_blur_min*2,\n",
    "                                            initial_lr=1e-4,\n",
    "                                            lr = 1e-4,\n",
    "                                            lr_lin = 1e-4,\n",
    "                                            nb_levels=5,\n",
    "                                            conv_size=3,\n",
    "                                            num_epochs=40000,\n",
    "                                            num_bg_labels=16,\n",
    "                                            nb_conv_per_level=2):\n",
    "\n",
    "\n",
    "    input_img = Input(shape=(dimx, dimy, dimz, 1))\n",
    "    \n",
    "    unet_model = vxm.networks.Unet(inshape=(dimx, dimy, dimz, 1), nb_features=(en, de), \n",
    "                                   nb_conv_per_level=nb_conv_per_level,\n",
    "                                   final_activation_function='softmax')\n",
    "    if gmm:\n",
    "\n",
    "        # input_img = Input(shape=(*in_shape,1))\n",
    "        input_brain = get_brain_tf(input_img)\n",
    "        _, y_brain = model1(input_brain)\n",
    "\n",
    "        input_fov = get_fov_tf(input_img)\n",
    "        \n",
    "        _, y_fov = model2(input_fov)\n",
    "        # input_final = y_brain + y_fov * (y_brain == 0)\n",
    "        input_final = y_brain + tf.cast(y_fov, dtype=tf.int32) * tf.cast(y_brain == 0, dtype=tf.int32)\n",
    "\n",
    "        generated_img, y = labels_to_image_model(input_final)\n",
    "        segmentation = unet_model(generated_img)\n",
    "        combined_model = Model(inputs=input_img, outputs=segmentation)\n",
    "    elif norm:\n",
    "        x = BatchNormalization(axis=-1)(input_img)  # Change the axis according to your needs\n",
    "        segmentation = unet_model(x)\n",
    "        combined_model = Model(inputs=input_img, outputs=segmentation)\n",
    "    else:\n",
    "        segmentation = unet_model(input_img)\n",
    "        combined_model = Model(inputs=input_img, outputs=segmentation)\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        combined_model.load_weights(checkpoint_path)\n",
    "        print(\"Loaded weights from the checkpoint and continued training.\")\n",
    "    else:\n",
    "        # print(checkpoint_path)\n",
    "        print(\"Checkpoint file not found.\")\n",
    "    unet_model = combined_model.layers[-1]\n",
    "\n",
    "    return unet_model\n",
    "\n",
    "\n",
    "num_row = 3\n",
    "per_row = 10\n",
    "\n",
    "    \n",
    "def calculate_dice_coefficient(ground_truth, predicted):\n",
    "    intersection = np.sum(np.logical_and(ground_truth, predicted))\n",
    "    union = np.sum(np.logical_or(ground_truth, predicted))\n",
    "    dice_coefficient = (2.0 * intersection) / (union + intersection)\n",
    "    return dice_coefficient\n",
    "\n",
    "def print_row_dice_coefficients(i, row_dice_coefficients):\n",
    "    formatted_dice = [f\"   {dice:.4f}\" for j, dice in enumerate(row_dice_coefficients)]\n",
    "    num_spaces = num_row-1\n",
    "    padding_left = 0\n",
    "    padding_right = 0\n",
    "\n",
    "    formatted_output = f\"{' ' * padding_left}{'       '.join(formatted_dice)}{' ' * padding_right}\"\n",
    "    print(f' {formatted_output}')\n",
    "    \n",
    "def visualize(combined_model,image,mask, id):\n",
    "    crop_img = image.resize([1.5, 1.5, 1.5]).reshape((dim_, dim_, dim_,1))    \n",
    "    crop_data = minmax_norm(crop_img.data)\n",
    "    \n",
    "    prediction_one_hot = process_image(crop_data, combined_model)\n",
    "    predictions_argmax = np.argmax(prediction_one_hot, axis=-1)\n",
    "    prediction = np.squeeze(predictions_argmax, axis=0)\n",
    "\n",
    "    prediction = sf.Volume(prediction)#.reshape(mask.data.shape)#.resample_like(mask)\n",
    "    # mask.data[mask.data != 0] = 1\n",
    "    hard_dice_score = my_hard_dice(mask.data, prediction.data)\n",
    "    \n",
    "    print(f\"Hard Dice Coefficient: {hard_dice_score}\")\n",
    "\n",
    "    nib.save(nib.Nifti1Image(crop_img.astype(np.float32), np.eye(4), header=None), f\"output/crop_img_{id}.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(prediction.data.astype(np.int32), np.eye(4), header=None), f\"output/pred_{id}.nii.gz\")\n",
    "    nib.save(nib.Nifti1Image(mask.data.astype(np.int32), np.eye(4), header=None), f\"output/mask_{id}.nii.gz\")\n",
    "\n",
    "    ne.plot.volume3D(crop_img);\n",
    "    ne.plot.volume3D(mask);\n",
    "    ne.plot.volume3D(prediction);\n",
    "\n",
    "from scipy.ndimage import binary_closing\n",
    "from scipy import ndimage\n",
    "\n",
    "def calculate_hard_dice(image, model, mask):\n",
    "    # mask = sf.load_volume(mask_filename).reshape((dim_, dim_, dim_))\n",
    "\n",
    "\n",
    "    prediction_one_hot = process_image(image.data, model)\n",
    "    predictions_argmax = np.argmax(prediction_one_hot, axis=-1)\n",
    "    prediction = np.squeeze(predictions_argmax, axis=0)\n",
    "    mask.data[mask.data != 0] = 1\n",
    "    # kernel = np.ones((5, 5, 5), np.uint8)  # Adjust the kernel size as needed for 3D\n",
    "    # for i in range(5):\n",
    "    dial_num = 4\n",
    "    prediction = binary_dilation(prediction, iterations=dial_num)\n",
    "    prediction = ndimage.binary_fill_holes(prediction).astype(int)\n",
    "    prediction = binary_erosion(prediction, iterations=dial_num)\n",
    "    prediction = getLargestCC(prediction)\n",
    "\n",
    "    # prediction = ndimage.binary_fill_holes(prediction).astype(int)\n",
    "    # prediction = getLargestCC(prediction)\n",
    "    # prediction = binary_dilation(prediction, iterations=10)\n",
    "    # prediction = binary_erosion(prediction, iterations=10)\n",
    "    \n",
    "    return my_hard_dice(prediction.flatten(),mask.data.flatten())\n",
    "\n",
    "def evaluate(validation_folder_path, combined_model , new_voxsize):\n",
    "    subfolders = [f.name for f in os.scandir(validation_folder_path) if f.is_dir()]\n",
    "\n",
    "\n",
    "    \n",
    "    b_hard_dice_scores=[]\n",
    "\n",
    "    b_salehi_dice_scores=[]\n",
    "    b_kevin_dice_scores=[]\n",
    "    b_ebner_dice_scores=[]\n",
    "\n",
    "    latest_images=[]\n",
    "    latest_masks=[]\n",
    "    \n",
    "    end_epoch = 0 + step_size * ((initial_epoch) // step_size)\n",
    "    \n",
    "\n",
    "    \n",
    "    b_10_hard_dice_scores = []\n",
    "    b_10_salehi_dice_scores = []\n",
    "    b_10_ebner_dice_scores = []\n",
    "    b_10_kevin_dice_scores = []\n",
    "\n",
    "    for folder in subfolders:\n",
    "        # print(folder)\n",
    "        folder_path = os.path.join(validation_folder_path, folder)\n",
    "        # filename = os.path.join(folder_path,\"image.mgz\")\n",
    "        if os.path.exists(os.path.join(folder_path, \"image.mgz\")): \n",
    "            filename = os.path.join(folder_path, \"image.mgz\") \n",
    "        else:\n",
    "            filename = os.path.join(folder_path, \"image.nii.gz\")\n",
    "# os.path.join(folder_path, \"image.nii.gz\") if os.path.exists(os.path.join(folder_path, \"image.nii.gz\"))\n",
    "\n",
    "        mask_filename = os.path.join(folder_path,\"manual.nii.gz\")\n",
    "        ebner_mask_filename = os.path.join(folder_path,\"ebner.nii.gz\")\n",
    "        kevin_mask_filename = os.path.join(folder_path,\"keraudren.nii.gz\")\n",
    "        salehi_mask_filename = os.path.join(folder_path,\"salehi.nii.gz\")\n",
    "\n",
    "        \n",
    "        image = sf.load_volume(filename)\n",
    "        orig_voxsize = image.geom.voxsize\n",
    "        if validation_folder_path == \"EPI_150\":\n",
    "            new_voxsize = [dynamic_resize(image)]*3\n",
    "        else:\n",
    "            new_voxsize = [dynamic_resize(image)]*3\n",
    "\n",
    "        crop_img = image.resize([orig_voxsize[0],orig_voxsize[1],new_voxsize[-1]], method=\"linear\")\n",
    "        crop_img = crop_img.resize(new_voxsize, method=\"linear\").reshape([dim_, dim_, dim_])\n",
    "        # crop_data = minmax_norm(crop_img.data)\n",
    "        crop_data = percentile_norm(crop_img.data)\n",
    "        # crop_data = minmax_norm(crop_data)\n",
    "    \n",
    "        mask = sf.load_volume(mask_filename).resize([orig_voxsize[0],orig_voxsize[1],new_voxsize[-1]], method=\"linear\")\n",
    "        mask = mask.resize(new_voxsize).reshape([dim_, dim_, dim_, 1])\n",
    "\n",
    "        salehi_mask = sf.load_volume(salehi_mask_filename).resize([orig_voxsize[0],orig_voxsize[1],new_voxsize[-1]], method=\"linear\")\n",
    "        ebner_mask = sf.load_volume(ebner_mask_filename).resize([orig_voxsize[0],orig_voxsize[1],new_voxsize[-1]], method=\"linear\")\n",
    "        kevin_mask = sf.load_volume(kevin_mask_filename).resize([orig_voxsize[0],orig_voxsize[1],new_voxsize[-1]], method=\"linear\")\n",
    "\n",
    "        salehi_mask = salehi_mask.resize(new_voxsize).reshape([dim_, dim_, dim_, new_voxsize[-1]])\n",
    "        ebner_mask = ebner_mask.resize(new_voxsize).reshape([dim_, dim_, dim_, 1])\n",
    "        kevin_mask = kevin_mask.resize(new_voxsize).reshape([dim_, dim_, dim_, 1])\n",
    "\n",
    "        mask.data[mask.data != 0] = 1\n",
    "        hard_dice_score = calculate_hard_dice(crop_img, combined_model, mask)\n",
    "        # mom = int(folder.split(\"_\")[1])\n",
    "        \n",
    "        salehi_dice_score = my_hard_dice(salehi_mask.data, mask.data)\n",
    "        ebner_dice_score = my_hard_dice(ebner_mask.data, mask.data)\n",
    "        kevin_dice_score = my_hard_dice(kevin_mask.data, mask.data)\n",
    "\n",
    "        print(\"file: {:s}, Dice: {:.4f}, Kevin: {:.4f}, Ebner: {:.4f}, Salehi: {:.4f}\".format(\n",
    "            folder, hard_dice_score, kevin_dice_score, ebner_dice_score, salehi_dice_score\n",
    "        ))\n",
    "        # print(folder, hard_dice_score)\n",
    "        b_10_hard_dice_scores.append(hard_dice_score)\n",
    "\n",
    "        b_10_salehi_dice_scores.append(salehi_dice_score)\n",
    "        b_10_ebner_dice_scores.append(ebner_dice_score)\n",
    "        b_10_kevin_dice_scores.append(kevin_dice_score)\n",
    "\n",
    "    b_hard_dice_scores= (np.mean(b_10_hard_dice_scores),np.std(b_10_hard_dice_scores))\n",
    "    \n",
    "    b_salehi_dice_scores=(np.mean(b_10_salehi_dice_scores),np.std(b_10_salehi_dice_scores))\n",
    "    b_kevin_dice_scores = (np.mean(b_10_kevin_dice_scores),np.std(b_10_kevin_dice_scores))\n",
    "    b_ebner_dice_scores= (np.mean(b_10_ebner_dice_scores),np.std(b_10_ebner_dice_scores))\n",
    "\n",
    "    return b_hard_dice_scores , b_salehi_dice_scores, b_kevin_dice_scores, b_ebner_dice_scores\n",
    "        \n",
    "def load_models():\n",
    "    with open(\"params_192.json\", \"r\") as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    model1_config = config[\"brain\"]\n",
    "    model2_config = config[\"body\"]\n",
    "    model3_config = config[\"labels_to_image_model\"]\n",
    "    model4_config = config[\"labels_to_image_model_with_shapes\"]\n",
    "    \n",
    "    # Convert labels_out keys to integers for all models\n",
    "    model1_config[\"labels_out\"] = {int(key): value for key, value in model1_config[\"labels_out\"].items()}\n",
    "    model2_config[\"labels_out\"] = {int(key): value for key, value in model2_config[\"labels_out\"].items()}\n",
    "    model3_config[\"labels_out\"] = {int(key): value for key, value in model3_config[\"labels_out\"].items()}\n",
    "    \n",
    "    model4_config[\"labels_out\"] = {int(key): value for key, value in model3_config[\"labels_out\"].items()}\n",
    "    # Now you have the modified configuration\n",
    "    # Brain\n",
    "    model1 = create_model(model1_config)\n",
    "    # Body\n",
    "    model2 = create_model(model2_config)\n",
    "    # Model\n",
    "    labels_to_image_model = create_model(model3_config)\n",
    "    return model1, model2, labels_to_image_model\n",
    "model1, model2, labels_to_image_model = load_models()\n",
    "import os, shutil, glob\n",
    "\n",
    "\n",
    "gmm = False\n",
    "synth=True\n",
    "conc=True\n",
    "norm=True\n",
    "if gmm:\n",
    "    step_size=1000\n",
    "    # models_dir='models_synth_gmm_mgh_brain_mgh_body_192'\n",
    "    if synth:\n",
    "        # models_dir='models_synth_gmm_feta_mgh_body_192'\n",
    "        models_dir='models_synth_gmm_mgh_brain_mgh_body_192'\n",
    "elif conc:\n",
    "    step_size=3000\n",
    "    if synth and norm:\n",
    "        models_dir='models_synth_less_conc_norm_shapes_feta_192'\n",
    "    elif synth and not norm:\n",
    "        models_dir='models_synth_less_conc_shapes_feta_192'\n",
    "    else:\n",
    "        models_dir='models_less_conc_shapes_feta_192'\n",
    "else:\n",
    "    # models_dir='models_shapes_feta_192'\n",
    "    if synth:\n",
    "        step_size=100\n",
    "        models_dir='models_synth_shapes_feta_192'\n",
    "    else:\n",
    "        step_size=500\n",
    "        models_dir='models_shapes_feta_192'\n",
    "\n",
    "\n",
    "if synth:\n",
    "    en = [16, 16, 32 ,32 ,64 ,64 ,64 ,64 ,64 ,64 ,64 ,64 ,64]\n",
    "    de = [64 ,64 ,64 ,64, 64 ,64 ,64, 64, 64, 32 ,32 ,16 ,16 ,2]\n",
    "else:\n",
    "    en=[16,16, 32,32, 64,64,128,128, 192,192]\n",
    "    de=[192,192, 128,128,64,64,32,32,16,16,2]\n",
    "\n",
    "\n",
    "nb_features = '_'.join(map(str, en))\n",
    "dim_=192\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "last_models_hard_dice_scores = []\n",
    "n = 500\n",
    "# for i in range(latest_epoch, latest_epoch - n, -10):\n",
    "latest_weight = max(glob.glob(os.path.join(models_dir, 'weights_epoch_*.h5')), key=os.path.getctime, default=None)\n",
    "\n",
    "match = re.search(r'(\\d+)', latest_weight.split(\"/\")[1])\n",
    "initial_epoch = int(match.group())\n",
    "\n",
    "checkpoint_path=models_dir+'/weights_epoch_'+str(initial_epoch)+'.h5'\n",
    "print(checkpoint_path)\n",
    "combined_model = load_model3D(checkpoint_path,gmm,norm , num_dim=3, dimx=dim_,\n",
    "                                                       dimy=dim_,\n",
    "                                                       dimz=dim_)\n",
    "\n",
    "# new_voxsize = [1.25,1.25,1.25] # for MGH\n",
    "new_voxsize = [0.65,0.65,0.65] # For EPI\n",
    "# validation_folder_path_1=\"test/haste_trim2\"\n",
    "# validation_folder_path_2=\"test/haste_trim3\"\n",
    "\n",
    "validation_folder_path_1=\"validation2/haste_trim2\"\n",
    "validation_folder_path_2=\"validation2/haste_trim3\"\n",
    "\n",
    "validation_folder_path_3=\"EPI_150\"\n",
    "\n",
    "# b2_fstrip, b2_salehi, b2_kevin , b2_ebner= evaluate(validation_folder_path_1,combined_model, new_voxsize)\n",
    "# b3_fstrip, b3_salehi, b3_kevin , b3_ebner = evaluate(validation_folder_path_2,combined_model,new_voxsize)\n",
    "\n",
    "epi_fstrip, epi_salehi, epi_kevin , epi_ebner = evaluate(validation_folder_path_3,combined_model,new_voxsize)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data with one mean and one std for each baseline\n",
    "second_trimester_data = {\n",
    "    'Salehi': b2_salehi,\n",
    "    'Keraudren': b2_kevin,\n",
    "    'Ebner': b2_ebner,\n",
    "    'f-Strip': b2_fstrip\n",
    "}\n",
    "\n",
    "third_trimester_data = {\n",
    "    'Salehi': b3_salehi,\n",
    "    'Keraudren': b3_kevin,\n",
    "    'Ebner': b3_ebner,\n",
    "    'f-Strip': b3_fstrip\n",
    "}\n",
    "\n",
    "epi_data = {\n",
    "    'Salehi': epi_salehi,\n",
    "    'Keraudren': epi_kevin,\n",
    "    'Ebner': epi_ebner,\n",
    "    'f-Strip': epi_fstrip\n",
    "}\n",
    "\n",
    "# Create separate plots for each trimester\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))\n",
    "\n",
    "# Rectangular box plot for the second trimester\n",
    "bplot1 = axes[0].boxplot(list(second_trimester_data.values()),\n",
    "                          vert=True,\n",
    "                          patch_artist=True,\n",
    "                          labels=list(second_trimester_data.keys()))  # will be used to label x-ticks\n",
    "\n",
    "# Set different colors for boxes\n",
    "colors1 = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "for patch, color in zip(bplot1['boxes'], colors1):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "axes[0].set_title('Second Trimester', fontsize=18)\n",
    "axes[0].set_ylabel('Dice Score', fontsize=15)\n",
    "axes[0].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "# Rectangular box plot for the third trimester\n",
    "bplot2 = axes[1].boxplot(list(third_trimester_data.values()),\n",
    "                          vert=True,\n",
    "                          patch_artist=True,\n",
    "                          labels=list(third_trimester_data.keys()))  # will be used to label x-ticks\n",
    "\n",
    "# Set different colors for boxes\n",
    "colors2 = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "for patch, color in zip(bplot2['boxes'], colors2):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "axes[1].set_title('Third Trimester', fontsize=18)\n",
    "axes[1].set_ylabel('Dice Score', fontsize=15)\n",
    "axes[1].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "# Rectangular box plot for epi_data\n",
    "bplot3 = axes[2].boxplot(list(epi_data.values()),\n",
    "                          vert=True,\n",
    "                          patch_artist=True,\n",
    "                          labels=list(epi_data.keys()))  # will be used to label x-ticks\n",
    "\n",
    "# Set different colors for boxes\n",
    "colors3 = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "for patch, color in zip(bplot3['boxes'], colors3):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "axes[2].set_title('Epi Data', fontsize=18)\n",
    "axes[2].set_ylabel('Dice Score', fontsize=15)\n",
    "axes[2].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20932e01-b30a-407f-a614-023bed2a487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = sf.load_volume(\"test/haste_trim3/mom_011__30wk__8T2_Haste_Sag_mm_400_FOV/image.mgz\")\n",
    "# mask = np.zeros(image.shape)\n",
    "# nib.save(nib.Nifti1Image(mask.astype(np.int32), np.eye(4), header=None), f\"test/haste_trim3/mom_011__30wk__8T2_Haste_Sag_mm_400_FOV/salehi.nii.gz\")\n",
    "# nib.save(nib.Nifti1Image(mask.astype(np.int32), np.eye(4), header=None), f\"test/haste_trim3/mom_011__30wk__8T2_Haste_Sag_mm_400_FOV/ebner.nii.gz\")\n",
    "# nib.save(nib.Nifti1Image(mask.astype(np.int32), np.eye(4), header=None), f\"test/haste_trim3/mom_011__30wk__8T2_Haste_Sag_mm_400_FOV/keraudren.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9db45b2-afe9-4eb4-b921-6705e291bea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3695936228104438, 0.259286525217361)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_fstrip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49ec75bb-c889-48bb-a0ef-baed2c033fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfolders = [f.name for f in os.scandir(\"EPI_256/labels\") if f.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f860252-190a-4cb4-a20e-5807ad07e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in subfolders:\n",
    "#     folder_path = os.path.join(\"EPI\", folder)\n",
    "#     filename = os.path.join(folder_path,\"image.nii.gz\")\n",
    "#     image = sf.load_volume(filename)\n",
    "#     vsize = image.geom.voxsize\n",
    "#     i_shape = image.shape\n",
    "#     image= image.reshape([256,256,i_shape[2]])\n",
    "#     # sf.save()\n",
    "#     nib.save(nib.Nifti1Image(image, np.eye(4)), f\"EPI_256/\"+folder+\".nii.gz\")\n",
    "\n",
    "#     .reshape([256,256, ])\n",
    "    \n",
    "# image = sf.load_volume(\"EPI/T2sEPI_007_21w4d_041_f04/image.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "33806591-ed51-4ecf-8bbd-0c8b1297afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape\n",
    "# /autofs/space/bal_004/users/jd1677/kevin-2016/data/b\n",
    "# image = sf.load_volume(\"/autofs/space/bal_004/users/jd1677/synthstrip/EPI_256/T2sEPI_020_21w1d_035_f15/image.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9c52d7fa-d809-483c-829c-b41a879f8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nib.save(nib.Nifti1Image(np.zeros(image.shape), np.eye(4)), \"/autofs/space/bal_004/users/jd1677/synthstrip/EPI_256/T2sEPI_020_21w1d_035_f15/salehi.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8a1c88f-bcec-4bdb-8c5a-39aeac7f9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a= np.zeros(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c53571e9-e43d-4415-9cb8-0770a9368659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 128)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b408898f-560b-48bd-9304-7d96917ec459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 70)\n",
      "(256, 256, 100)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 96)\n",
      "(256, 256, 90)\n",
      "(256, 256, 70)\n",
      "(256, 256, 90)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 94)\n",
      "(256, 256, 57)\n",
      "(256, 256, 90)\n",
      "(256, 256, 70)\n",
      "(256, 256, 88)\n",
      "(256, 256, 70)\n",
      "(256, 256, 40)\n",
      "(256, 256, 70)\n",
      "(256, 256, 66)\n",
      "(256, 256, 70)\n",
      "(256, 256, 99)\n",
      "(256, 256, 80)\n",
      "(256, 256, 58)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 46)\n",
      "(256, 256, 78)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 80)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 74)\n",
      "(256, 256, 128)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 85)\n",
      "(256, 256, 40)\n",
      "(256, 256, 80)\n",
      "(256, 256, 66)\n",
      "(256, 256, 70)\n",
      "(256, 256, 128)\n",
      "(256, 256, 90)\n",
      "(256, 256, 80)\n",
      "(256, 256, 74)\n",
      "(256, 256, 48)\n",
      "(256, 256, 70)\n",
      "(256, 256, 52)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 80)\n",
      "(256, 256, 85)\n",
      "(256, 256, 90)\n",
      "(256, 256, 75)\n",
      "(256, 256, 58)\n",
      "(256, 256, 63)\n",
      "(256, 256, 37)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 40)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 60)\n",
      "(256, 256, 90)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 32)\n",
      "(256, 256, 62)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 88)\n",
      "(256, 256, 50)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 74)\n",
      "(256, 256, 51)\n",
      "(256, 256, 80)\n",
      "(256, 256, 100)\n",
      "(256, 256, 100)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 50)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 47)\n",
      "(256, 256, 80)\n",
      "(256, 256, 76)\n",
      "(256, 256, 70)\n",
      "(256, 256, 90)\n",
      "(256, 256, 70)\n",
      "(256, 256, 80)\n",
      "(256, 256, 86)\n",
      "(256, 256, 55)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 90)\n",
      "(256, 256, 70)\n",
      "(256, 256, 90)\n",
      "(256, 256, 60)\n",
      "(256, 256, 67)\n",
      "(256, 256, 58)\n",
      "(256, 256, 70)\n",
      "(256, 256, 99)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 67)\n",
      "(256, 256, 65)\n",
      "(256, 256, 70)\n",
      "(256, 256, 60)\n",
      "(256, 256, 70)\n",
      "(256, 256, 110)\n",
      "(256, 256, 52)\n",
      "(256, 256, 55)\n",
      "(256, 256, 76)\n",
      "(256, 256, 50)\n",
      "(256, 256, 70)\n",
      "(256, 256, 85)\n",
      "(256, 256, 66)\n",
      "(256, 256, 70)\n",
      "(256, 256, 70)\n",
      "(256, 256, 120)\n",
      "(256, 256, 70)\n",
      "(256, 256, 80)\n",
      "(256, 256, 77)\n",
      "(256, 256, 80)\n",
      "(256, 256, 63)\n",
      "(256, 256, 55)\n",
      "(256, 256, 70)\n",
      "(256, 256, 45)\n",
      "(256, 256, 50)\n",
      "(256, 256, 40)\n",
      "(256, 256, 76)\n",
      "(256, 256, 70)\n",
      "(256, 256, 76)\n",
      "(256, 256, 80)\n",
      "(256, 256, 51)\n",
      "(256, 256, 53)\n"
     ]
    }
   ],
   "source": [
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# onlyfiles = [f for f in listdir(\"EPI_256/labels\") if isfile(join(\"EPI_256/labels\", f))]\n",
    "# for file in onlyfiles:\n",
    "#     folder_path = os.path.join(\"EPI_256/labels\", file)\n",
    "#     # filename = os.path.join(folder_path,\"image.nii.gz\")\n",
    "#     image = sf.load_volume(folder_path)\n",
    "#     # vsize = image.geom.voxsize\n",
    "#     i_shape = image.shape\n",
    "#     image= image.reshape([256,256,i_shape[2]])\n",
    "#     # sf.save()\n",
    "#     print(image.shape)\n",
    "#     nib.save(nib.Nifti1Image(image, np.eye(4)), f\"EPI_256/labels/\"+file)\n",
    "\n",
    "#     # .reshape([256,256, ])\n",
    "    \n",
    "# # image = sf.load_volume(\"EPI/T2sEPI_007_21w4d_041_f04/image.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23056015-44c5-47f7-9c64-c22e59b60245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
