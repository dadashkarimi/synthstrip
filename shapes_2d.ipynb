{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bcc5d7-6e13-47ed-9fd4-61c0336cfd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 11:46:31.321326: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-23 11:46:31.367928: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Issue loading cv2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit'\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from neurite.tf import models  # Assuming the module's location\n",
    "import voxelmorph.tf.losses as vtml\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import neurite as ne\n",
    "import sys\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from neurite_sandbox.tf.models import labels_to_labels\n",
    "from neurite_sandbox.tf.utils.augment import add_outside_shapes\n",
    "from neurite.tf.utils.augment import draw_perlin_full\n",
    "\n",
    "import tensorflow.keras.layers as KL\n",
    "import voxelmorph as vxm\n",
    "from utils import *\n",
    "import argparse\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import pathlib\n",
    "import surfa as sf\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce24b2a-2bc9-414b-8302-f26aaa8637a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feta = pathlib.Path('feta_resized_192')\n",
    "feta_files = list(feta.glob('*.nii.gz'))\n",
    "feta_label_maps = [np.uint8(f.dataobj) for f in map(nib.load, feta_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22b50ade-f2b6-4abb-a75b-25a0d4335363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 192, 192, 192, 1)\n",
      "(None, 192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n",
      "(192, 192, 192, 1)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "each slice has to be 2d or RGB (3 channels)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m per_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_row \u001b[38;5;241m*\u001b[39m per_row, per_row):\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mper_row\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmaps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# ne.plot.slices(masks[i:i + per_row], cmaps=['gray'])\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# ne.plot.slices(generated_img)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# generated_img= extract_slices(generated_img,slice_stride)\u001b[39;00m\n",
      "File \u001b[0;32m/autofs/space/bal_004/users/jd1677/neurite/neurite/py/plot.py:54\u001b[0m, in \u001b[0;36mslices\u001b[0;34m(slices_in, titles, cmaps, norms, do_colorbars, grid, width, show, axes_off, plot_block, facecolor, imshow_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m si, slice_in \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(slices_in):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(slice_in\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(slice_in\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m slice_in\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \\\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach slice has to be 2d or RGB (3 channels)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_check\u001b[39m(inputs, nb_plots, name, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' change input from None/single-link '''\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: each slice has to be 2d or RGB (3 channels)"
     ]
    }
   ],
   "source": [
    "def extract_slices(inp,stride):\n",
    "    out = tf.transpose(inp[0], perm=(2, 0, 1, 3))\n",
    "    return out#[:,:,stride]\n",
    "    \n",
    "with open(\"params_192.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "num_shapes = 6\n",
    "\n",
    "model4_config = config[\"labels_to_image_model_with_shapes\"]\n",
    "num_labels=9\n",
    "\n",
    "model4_config[\"labels_out\"] = {int(key): value for key, value in model4_config[\"labels_out\"].items()}\n",
    "in_shape=model4_config[\"in_shape\"]\n",
    "slice_stride = model4_config[\"slice_stride_min\"]\n",
    "\n",
    "labels_to_image_model_with_shapes = create_model(model4_config)\n",
    "\n",
    "brain_maps = get_brain(feta_label_maps)\n",
    "shapes = [draw_shapes(in_shape, num_labels) for _ in range(num_shapes)]\n",
    "\n",
    "shapes = map(np.squeeze, shapes)\n",
    "shapes = map(np.uint8, shapes)\n",
    "shapes = [f + 7 + 1 for f in shapes]\n",
    "gen = generator(brain_maps, shapes)\n",
    "slice_stride=10\n",
    "images = []\n",
    "masks = []\n",
    "for i in range(16):\n",
    "    # Generate image from the generator\n",
    "    im = next(gen)\n",
    "    # print(im.shape)\n",
    "    generated_img, y = labels_to_image_model_with_shapes(im)\n",
    "\n",
    "    # Extract slices and squeeze the last axis\n",
    "    generated_img = extract_slices(generated_img, slice_stride)\n",
    "    y = extract_slices(y, slice_stride)\n",
    "    print(generated_img.shape)\n",
    "    generated_img = np.squeeze(generated_img, axis=-1)\n",
    "    images.append(generated_img)\n",
    "    # print(y.shape)\n",
    "    # y= np.squeeze(np.squeeze(y, axis=0),axis=-1)\n",
    "    # y= np.squeeze(y, axis=-1)\n",
    "    masks.append(y)\n",
    "\n",
    "num_row = 2\n",
    "per_row = 8\n",
    "for i in range(0, num_row * per_row, per_row):\n",
    "    ne.plot.slices(images[i:i + per_row], cmaps=['gray'])\n",
    "    # ne.plot.slices(masks[i:i + per_row], cmaps=['gray'])\n",
    "    \n",
    "# ne.plot.slices(generated_img)\n",
    "\n",
    "# im = next(gen)\n",
    "# generated_img, y = labels_to_image_model_with_shapes(im)\n",
    "\n",
    "# generated_img= extract_slices(generated_img,slice_stride)\n",
    "# generated_img = np.squeeze(generated_img, axis=-1)\n",
    "# print(generated_img.shape)\n",
    "# ne.plot.slices(generated_img)\n",
    "# unet_model = vxm.networks.Unet(inshape=(*in_shape_3d, 1), nb_features=(en, de), \n",
    "#                                nb_conv_per_level=nb_conv_per_level,\n",
    "#                                final_activation_function='softmax')\n",
    "# input_img = Input(shape=(*in_shape_3d,1))\n",
    "\n",
    "# if args.shapes:\n",
    "#     generated_img, y = labels_to_image_model_with_shapes(input_img)\n",
    "\n",
    "# generated_img= extract_slices(generated_img,slice_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd60abe-92aa-4947-ade7-224d90faa353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "print(masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a2007-bd83-4e81-8396-c15ba8cfb46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
