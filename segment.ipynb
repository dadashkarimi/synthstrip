{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "250d24a2-a8ae-4b5d-aa55-8afc24c599f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurite as ne\n",
    "import sys\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.models import load_model\n",
    "from neurite_sandbox.tf.models import labels_to_labels\n",
    "import nibabel as nib\n",
    "import tqdm\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import neurite as ne\n",
    "import voxelmorph as vxm\n",
    "from utils import *\n",
    "import pathlib\n",
    "import surfa as sf\n",
    "\n",
    "\n",
    "feta = pathlib.Path('/autofs/space/bal_004/users/jd1677/synthstrip/feta_3d')\n",
    "files = list(feta.glob('sub-???/anat/sub-???_rec-mial_dseg.nii.gz'))\n",
    "label_maps = [np.uint8(f.dataobj) for f in map(nib.load, files)]\n",
    "\n",
    "labels = np.unique(label_maps)\n",
    "num_labels=8\n",
    "\n",
    "def segment_brain(image, brain_mask, labels_in):\n",
    "    label_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    unique_intensities = np.unique(image[brain_mask == 1])\n",
    "    label_map[image == unique_intensities] = labels_in[:max(labels)]\n",
    "    label_map[image == unique_intensities] = labels_in[max(labels):]\n",
    "    return label_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ad5635f-4762-495e-b6b6-e18297a33a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sf.load_volume('example/mom_010_22_week_2__body_T2_Hast_mm_400_FOV/22_week_2__body_T2_Hast_mm_400_FOV.mgz')\n",
    "mask  = sf.load_volume('example/mom_010_22_week_2__body_T2_Hast_mm_400_FOV/manual_masks_b2_mom_010_22_week_2__body_T2_Hast_mm_400_FOV_segment.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a7aed23-5741-4333-ac52-e51d560019c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels_in = range(max(labels) + num_labels + 1)\n",
    "print(labels_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd874d79-0007-4e26-9deb-7276d7a091fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def minmax_norm(x):\n",
    "    x = np.asarray(x,  dtype=np.float32)\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)#, axis=axis, keepdims=True)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "\n",
    "def segment_brain(image, brain_mask, labels_in):\n",
    "    # Flatten the image for K-Means clustering\n",
    "    image = minmax_norm(image)\n",
    "    image[image<0.02]=0\n",
    "    flattened_ibrain = image[brain_mask == 1].reshape(-1, 1)\n",
    "\n",
    "    num_clusters = 8#len(labels_in)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(flattened_ibrain)\n",
    "\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    brain_map[brain_mask == 1] = kmeans.labels_ #+ 1  # Adding 1 to start labels from 1\n",
    "\n",
    "    flattened_FOV = image[brain_mask == 0].reshape(-1, 1)\n",
    "\n",
    "    num_clusters = len(labels_in) - num_clusters #len(labels_in)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(flattened_FOV)\n",
    "\n",
    "    FOV_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    FOV_map[mask == 0] = kmeans.labels_ +num_clusters#+ #+ 1  # Adding 1 to start labels from 1\n",
    "    \n",
    "    FOV_map = FOV_map + brain_map\n",
    "    FOV_map[image==0]=0\n",
    "    return FOV_map\n",
    "\n",
    "fetus_label_map = segment_brain(image, mask, labels_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1a9f3a4-46c2-4e5f-8b1b-120913bd5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_img = sf.Volume(fetus_label_map)#nib.Nifti1Image(prediction.astype(np.float32), affine=np.eye(4))  # Assuming identity affine for simplicity\n",
    "nifti_img.geom = image.geom\n",
    "nifti_img = nifti_img.resample_like(image)\n",
    "nifti_img.astype(np.int32).save(\"output/fetus.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4fd040c9-2ff2-42c9-abfb-3b9255b7a179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.ndimage import binary_closing\n",
    "\n",
    "def fill_holes(label_map, iterations=1):\n",
    "    closed_map = binary_closing(label_map, iterations=iterations)\n",
    "    return closed_map.astype(np.uint8)\n",
    "\n",
    "# Usage\n",
    "filled_label_map = fill_holes(fetus_label_map, iterations=1)\n",
    "ne.plot.volume3D(filled_label_map, cmaps=['tab20c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9b7e92d-6df4-4360-9479-fcd341c2dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nifti_img = sf.Volume(smoothed_fetus_label_map)#nib.Nifti1Image(prediction.astype(np.float32), affine=np.eye(4))  # Assuming identity affine for simplicity\n",
    "# nifti_img.geom = image.geom\n",
    "# nifti_img = nifti_img.resample_like(image)\n",
    "# nifti_img.astype(np.int32).save(\"output/smoothed_fetus.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36a86eb9-128b-45a0-a192-7bd38933fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Please use `label` from the `scipy.ndimage` namespace, the `scipy.ndimage.measurements` namespace is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example/mom_101_36_week_2__T2_Haste_Sag_mm_400_FOV/36_week_2__T2_Haste_Sag_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_36_week_2__T2_Haste_Sag_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_012_19_week_4__body_T2_Hast_mm_400_FOV/19_week_4__body_T2_Hast_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_19_week_4__body_T2_Hast_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_007_22_week_5__T2_Haste_Ax__mm_400_FOV/22_week_5__T2_Haste_Ax__mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_22_week_5__T2_Haste_Ax__mm_400_FOV.mgz.nii.gz\n",
      "example/mom_100_30_week_2__T2_Haste_Sag_mm_400_FOV/30_week_2__T2_Haste_Sag_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_30_week_2__T2_Haste_Sag_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_108_32_week_2__T2_Haste_Sag_mm_400_FOV/32_week_2__T2_Haste_Sag_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_32_week_2__T2_Haste_Sag_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_110_28_week_2__T2_Haste_Sag_mm_400_FOV/28_week_2__T2_Haste_Sag_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_28_week_2__T2_Haste_Sag_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_103_34_week_2__T2_Haste_Sag_mm_400_FOV/34_week_2__T2_Haste_Sag_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_34_week_2__T2_Haste_Sag_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_010_22_week_2__body_T2_Hast_mm_400_FOV/22_week_2__body_T2_Hast_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_22_week_2__body_T2_Hast_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_001_19_week_3__T2_Haste_Cor_mm_400_FOV/19_week_3__T2_Haste_Cor_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_19_week_3__T2_Haste_Cor_mm_400_FOV.mgz.nii.gz\n",
      "example/mom_003_19_week_3__T2_Haste_Sag_mm_400_FOV/19_week_3__T2_Haste_Sag_mm_400_FOV.mgz\n",
      "fetus_gmm_label_map/fetus_label_map_19_week_3__T2_Haste_Sag_mm_400_FOV.mgz.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import surfa as sf\n",
    "import os\n",
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.ndimage import binary_erosion, binary_dilation\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.stats import mode\n",
    "\n",
    "def minmax_norm(x):\n",
    "    x = np.asarray(x,  dtype=np.float32)\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)#, axis=axis, keepdims=True)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "def segment_brain_with_ring(image, brain_mask, labels_in):\n",
    "    image = gaussian_filter(image.astype(np.uint8), sigma=2.8)\n",
    "    \n",
    "    image_norm = minmax_norm(image)\n",
    "\n",
    "    labeled_brain_mask, num_features = label(brain_mask)\n",
    "\n",
    "    largest_component = np.argmax(np.bincount(labeled_brain_mask.flat)[1:]) + 1\n",
    "\n",
    "    brain_mask = (labeled_brain_mask == largest_component).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    flattened_ibrain = image_norm[brain_mask == 1].reshape(-1, 1)\n",
    "\n",
    "    num_clusters1 = 7 # len(labels_in)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters1, random_state=0).fit(flattened_ibrain)\n",
    "\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    brain_map[brain_mask == 1] = kmeans.labels_ + 1  \n",
    "    brain_map[(brain_mask == 1) & (brain_map == 0)] = 1\n",
    "\n",
    "    expanded_ring = binary_dilation(brain_mask.astype(bool))\n",
    "    \n",
    "    # Apply additional smoothing to the binary dilation result\n",
    "    smoothed_ring = gaussian_filter(expanded_ring.astype(np.float32), sigma=4.0)\n",
    "    \n",
    "    # Threshold the smoothed ring to obtain a smoother transition\n",
    "    ring_mask = (smoothed_ring > 0.5).astype(np.uint8)\n",
    "    \n",
    "    brain_map[ring_mask] = 8  # You can use any non-zero label for the ring\n",
    "    brain_map[(brain_mask == 1) & (brain_map == 0)] = 1\n",
    "    \n",
    "\n",
    "    return brain_map\n",
    "\n",
    "\n",
    "def segment_FOV(image, brain_mask, labels_in):\n",
    "    image = gaussian_filter(image.astype(np.uint8), sigma=2.8)\n",
    "    \n",
    "    image_norm = minmax_norm(image)\n",
    "\n",
    "    labeled_brain_mask, num_features = label(brain_mask)\n",
    "\n",
    "    largest_component = np.argmax(np.bincount(labeled_brain_mask.flat)[1:]) + 1\n",
    "\n",
    "    brain_mask = (labeled_brain_mask == largest_component).astype(np.uint8)\n",
    "\n",
    "    flattened_ibrain = image_norm[brain_mask == 1].reshape(-1, 1)\n",
    "\n",
    "    num_clusters1 = 7\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters1, random_state=0).fit(flattened_ibrain)\n",
    "\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    brain_map[brain_mask == 1] = kmeans.labels_ + 1 \n",
    "\n",
    "\n",
    "    flattened_FOV = image_norm[brain_mask == 0].reshape(-1, 1)\n",
    "\n",
    "    num_clusters2 = len(labels_in) - num_clusters1 \n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters2, random_state=0).fit(flattened_FOV)\n",
    "\n",
    "    FOV_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    FOV_map[brain_mask == 0] = kmeans.labels_ +num_clusters1 + 1\n",
    "    \n",
    "    FOV_map = FOV_map + brain_map\n",
    "    FOV_map[image==0]=0\n",
    "    FOV_map[(brain_mask == 1) & (FOV_map == 0)] = 1\n",
    "\n",
    "    return FOV_map\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def segment_FOV_GMM(image, brain_mask, labels_in):\n",
    "    image = gaussian_filter(image.astype(np.uint8), sigma=2.8)\n",
    "\n",
    "    # Reshape the 3D image to a 1D array\n",
    "    image_flattened = image.flatten().reshape(-1, 1)\n",
    "\n",
    "    # Normalize the flattened image\n",
    "    image_norm = minmax_scale(image_flattened)\n",
    "\n",
    "    labeled_brain_mask, num_features = label(brain_mask)\n",
    "\n",
    "    largest_component = np.argmax(np.bincount(labeled_brain_mask.flat)[1:]) + 1\n",
    "\n",
    "    brain_mask = (labeled_brain_mask == largest_component).astype(np.uint8)\n",
    "\n",
    "    flattened_ibrain = image_norm[brain_mask.flatten() == 1].reshape(-1, 1)\n",
    "\n",
    "    num_clusters1 = 7\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_clusters1, max_iter=500, covariance_type='full').fit(flattened_ibrain)\n",
    "\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    brain_map[brain_mask == 1] = gmm.predict(flattened_ibrain) + 1 \n",
    "\n",
    "    flattened_FOV = image_norm[brain_mask.flatten() == 0].reshape(-1, 1)\n",
    "\n",
    "    num_clusters2 = len(labels_in) - num_clusters1 \n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_clusters2, max_iter=500, covariance_type='full').fit(flattened_FOV)\n",
    "\n",
    "    FOV_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    FOV_map[brain_mask == 0] = gmm.predict(flattened_FOV) + num_clusters1 + 1\n",
    "    \n",
    "    FOV_map = FOV_map + brain_map\n",
    "    FOV_map[image == 0] = 0\n",
    "    FOV_map[(brain_mask == 1) & (FOV_map == 0)] = 1\n",
    "\n",
    "    return FOV_map\n",
    "\n",
    "\n",
    "# Usage\n",
    "# filled_label_map = fill_holes(fetus_label_map, iterations=1)\n",
    "def segment_brain_GMM(image, brain_mask, labels_in):\n",
    "    image = gaussian_filter(image.astype(np.uint8), sigma=1.5)\n",
    "\n",
    "    image_norm = minmax_scale(image.flatten().reshape(-1, 1))\n",
    "\n",
    "    labeled_brain_mask, num_features = label(brain_mask)\n",
    "\n",
    "    largest_component = np.argmax(np.bincount(labeled_brain_mask.flat)[1:]) + 1\n",
    "\n",
    "    brain_mask = (labeled_brain_mask == largest_component).astype(np.uint8)\n",
    "\n",
    "    flattened_ibrain = image_norm[brain_mask.flatten() == 1].reshape(-1, 1)\n",
    "\n",
    "    num_clusters1 = 7\n",
    "\n",
    "    gmm = GaussianMixture(n_components=num_clusters1, max_iter=500, covariance_type='full').fit(flattened_ibrain)\n",
    "\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    brain_map[brain_mask == 1] = gmm.predict(flattened_ibrain) + 1\n",
    "\n",
    "    return brain_map\n",
    "    \n",
    "def segment_brain(image, brain_mask, labels_in):\n",
    "    image = gaussian_filter(image.astype(np.uint8), sigma=1.5)\n",
    "    \n",
    "    image_norm = minmax_norm(image)\n",
    "    flattened_ibrain = image_norm[brain_mask == 1].reshape(-1, 1)\n",
    "\n",
    "    num_clusters1 = 7#len(labels_in)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters1, random_state=0).fit(flattened_ibrain)\n",
    "\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    brain_map[brain_mask == 1] = kmeans.labels_ + 1  \n",
    "    brain_map[(brain_mask == 1) & (brain_map == 0)] = 1\n",
    "\n",
    "    return brain_map\n",
    "\n",
    "def segment_brain_fill_holes(image, brain_mask, labels_in):\n",
    "    image = gaussian_filter(image.astype(np.uint8), sigma=1.5)\n",
    "    \n",
    "    image_norm = minmax_norm(image)\n",
    "\n",
    "    labeled_brain_mask, num_features = label(brain_mask)\n",
    "\n",
    "    largest_component = np.argmax(np.bincount(labeled_brain_mask.flat)[1:]) + 1\n",
    "\n",
    "    new_brain_mask = (labeled_brain_mask == largest_component).astype(np.uint8)\n",
    "\n",
    "    flattened_ibrain = image_norm[new_brain_mask == 1].reshape(-1, 1)\n",
    "\n",
    "    num_clusters1 = 7 # len(labels_in)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters1, random_state=0).fit(flattened_ibrain)\n",
    "\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    brain_map[new_brain_mask == 1] = kmeans.labels_ + 1  # Adding 1 to start labels from 1\n",
    "    brain_map[(new_brain_mask == 1) & (brain_map == 0)] = 1\n",
    "    \n",
    "    return brain_map\n",
    "    \n",
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "\n",
    "from sklearn.cluster import OPTICS, DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import OPTICS, DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def segment_brain_parcellation(image, brain_mask, labels_in):\n",
    "    image_norm = minmax_norm(image)\n",
    "    flattened_ibrain = image_norm[brain_mask == 1].reshape(-1, 1)\n",
    "    optics = OPTICS(min_samples=2, xi=0.05, min_cluster_size=0.05)\n",
    "    optics.fit(flattened_ibrain)\n",
    "    dense_labels = optics.labels_[optics.labels_ != -1]\n",
    "    brain_map = np.zeros_like(image, dtype=np.uint8)\n",
    "    \n",
    "    for dense_label in np.unique(dense_labels):\n",
    "        cluster_mask = (optics.labels_ == dense_label)\n",
    "        dense_cluster = flattened_ibrain[cluster_mask].reshape(-1, 1)\n",
    "        dbscan = DBSCAN(eps=0.1, min_samples=5)\n",
    "        dbscan.fit(dense_cluster)\n",
    "        dense_cluster_labels = dbscan.labels_\n",
    "        brain_map[brain_mask == 1][cluster_mask] = dense_cluster_labels + 1\n",
    "\n",
    "    return brain_map\n",
    "\n",
    "\n",
    "\n",
    "def process_folder(folder_path, output_folder):\n",
    "    mgz_files = glob.glob(os.path.join(folder_path, '*.mgz'))\n",
    "    subject_id = 1\n",
    "    for mgz_file in mgz_files:\n",
    "        \n",
    "        print(mgz_file)\n",
    "        mask_file = glob.glob(os.path.join(folder_path, f'manual*.nii.gz'))[0]\n",
    "        # image = sf.Volume(nib.load(mgz_file).get_fdata()).resize([1,1,1]).reshape([256,256,256]).data\n",
    "        # sf.load_volume\n",
    "        # mask = sf.Volume(nib.load(mask_file).get_fdata()).resize([1,1,1]).reshape([256,256,256]).data\n",
    "        image = sf.load_volume(mgz_file).resize([1,1,1]).reshape([256,256,256]).data\n",
    "        mask = sf.load_volume(mask_file).resize([1,1,1]).reshape([256,256,256]).data\n",
    "        fetus_label_map = segment_FOV_GMM(image, mask, labels_in)\n",
    "        # fetus_label_map = segment_brain_fill_holes(image, mask, labels_in)\n",
    "\n",
    "        filename = os.path.basename(mgz_file)\n",
    "\n",
    "        output_file = os.path.join(output_folder, f'fetus_label_map_{filename}.nii.gz')\n",
    "\n",
    "        print(output_file)\n",
    "        nib.save(nib.Nifti1Image(fetus_label_map, np.eye(4)), output_file)\n",
    "        subject_id = int(subject_id)+ 1\n",
    "\n",
    "# Set the path to the example folder and output folder\n",
    "example_folder_path = 'example'\n",
    "output_folder_path = 'fetus_gmm_label_map'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# List of labels for segmentation\n",
    "# labels_in = range(1, 14)\n",
    "\n",
    "# Process each subfolder in the example folder\n",
    "for subfolder in os.listdir(example_folder_path):\n",
    "    subfolder_path = os.path.join(example_folder_path, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        process_folder(subfolder_path, output_folder_path)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0e1fc02-ef56-41b4-872a-7d9b8f0cdaf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimage_files\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_files' is not defined"
     ]
    }
   ],
   "source": [
    "image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac4f5f6d-24af-4ac3-a33e-a3270dd6923d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1866820150.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    label_maps = [np.uint8(sf.load_volume(str(file_path)).data) for file_path in mgh_files]|\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mgh = pathlib.Path('fetus_label_map')\n",
    "mgh_files = list(mgh.glob('*.nii.gz'))\n",
    "\n",
    "#label_maps = [np.uint8(f.dataobj) for f in map(nib.load, files)]\n",
    "\n",
    "# label_maps = [np.uint8(sf.load_volume(str(file_path)).reshape((dimx, dimy, dimz)).data) for file_path in files]\n",
    "label_maps = [np.uint8(sf.load_volume(str(file_path)).data) for file_path in mgh_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af909b2d-f08c-4fbe-b5c1-8a8c509d8aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
