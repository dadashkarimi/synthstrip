{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ff847-892a-4e7d-aa55-0447885df900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7c0cb8-ceee-4106-8805-93f2055d1d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 15:29:47.717965: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-28 15:29:47.762707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Issue loading cv2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models_shapes_feta_192/weights_epoch_1100.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 15:29:57.962039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 639 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:3d:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from the checkpoint and continued training.\n",
      "Loaded weights from the checkpoint and continued training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 15:30:01.455916: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 448.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-28 15:30:01.456242: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2024-02-28 15:30:01.480396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-02-28 15:30:01.592316: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 137.71MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-28 15:30:01.631144: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 137.71MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-28 15:30:01.631233: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 137.71MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-28 15:30:01.645377: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 137.71MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-02-28 15:30:11.703389: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 432.00MiB (rounded to 452984832)requested by op unet/unet_enc_conv_0_1/Conv3D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-02-28 15:30:11.703454: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-02-28 15:30:11.703468: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 28, Chunks in use: 27. 7.0KiB allocated for chunks. 6.8KiB in use in bin. 1.8KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703477: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 8, Chunks in use: 5. 4.8KiB allocated for chunks. 3.0KiB in use in bin. 2.8KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703483: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 6, Chunks in use: 5. 7.2KiB allocated for chunks. 6.2KiB in use in bin. 4.9KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703490: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 2, Chunks in use: 0. 4.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703499: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703506: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 2, Chunks in use: 1. 25.5KiB allocated for chunks. 12.0KiB in use in bin. 6.8KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703513: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703520: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 4, Chunks in use: 3. 193.5KiB allocated for chunks. 139.5KiB in use in bin. 108.0KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703527: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 5, Chunks in use: 3. 494.0KiB allocated for chunks. 324.0KiB in use in bin. 324.0KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703534: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 216.0KiB allocated for chunks. 216.0KiB in use in bin. 216.0KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703540: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 5, Chunks in use: 3. 1.90MiB allocated for chunks. 1.27MiB in use in bin. 1.27MiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703547: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 864.0KiB allocated for chunks. 864.0KiB in use in bin. 864.0KiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703553: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 2.95MiB allocated for chunks. 1.69MiB in use in bin. 1.69MiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703561: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 10, Chunks in use: 6. 32.48MiB allocated for chunks. 19.41MiB in use in bin. 17.30MiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703567: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 6.33MiB allocated for chunks. 6.33MiB in use in bin. 5.06MiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703574: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703580: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 1. 78.68MiB allocated for chunks. 27.00MiB in use in bin. 27.00MiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703586: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703592: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703598: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703605: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 515.38MiB allocated for chunks. 515.38MiB in use in bin. 432.00MiB client-requested in use in bin.\n",
      "2024-02-28 15:30:11.703616: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 432.00MiB was 256.00MiB, Chunk State: \n",
      "2024-02-28 15:30:11.703622: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 670564352\n",
      "2024-02-28 15:30:11.703631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000000 of size 1280 next 1\n",
      "2024-02-28 15:30:11.703637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000500 of size 256 next 2\n",
      "2024-02-28 15:30:11.703642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000600 of size 256 next 3\n",
      "2024-02-28 15:30:11.703648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000700 of size 256 next 5\n",
      "2024-02-28 15:30:11.703653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000800 of size 256 next 6\n",
      "2024-02-28 15:30:11.703658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000900 of size 256 next 4\n",
      "2024-02-28 15:30:11.703667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194000a00 of size 512 next 9\n",
      "2024-02-28 15:30:11.703672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000c00 of size 256 next 10\n",
      "2024-02-28 15:30:11.703677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194000d00 of size 512 next 16\n",
      "2024-02-28 15:30:11.703682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194000f00 of size 256 next 17\n",
      "2024-02-28 15:30:11.703688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194001000 of size 768 next 23\n",
      "2024-02-28 15:30:11.703693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194001300 of size 256 next 24\n",
      "2024-02-28 15:30:11.703698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194001400 of size 2304 next 39\n",
      "2024-02-28 15:30:11.703703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194001d00 of size 256 next 50\n",
      "2024-02-28 15:30:11.703709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194001e00 of size 256 next 72\n",
      "2024-02-28 15:30:11.703714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194001f00 of size 256 next 61\n",
      "2024-02-28 15:30:11.703719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194002000 of size 256 next 32\n",
      "2024-02-28 15:30:11.703724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194002100 of size 256 next 30\n",
      "2024-02-28 15:30:11.703730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194002200 of size 2304 next 43\n",
      "2024-02-28 15:30:11.703735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194002b00 of size 256 next 36\n",
      "2024-02-28 15:30:11.703740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194002c00 of size 1024 next 45\n",
      "2024-02-28 15:30:11.703745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194003000 of size 256 next 48\n",
      "2024-02-28 15:30:11.703751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194003100 of size 78080 next 13\n",
      "2024-02-28 15:30:11.703756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194016200 of size 256 next 62\n",
      "2024-02-28 15:30:11.703761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194016300 of size 256 next 63\n",
      "2024-02-28 15:30:11.703766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194016400 of size 256 next 64\n",
      "2024-02-28 15:30:11.703772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194016500 of size 13824 next 65\n",
      "2024-02-28 15:30:11.703777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194019b00 of size 512 next 75\n",
      "2024-02-28 15:30:11.703782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194019d00 of size 1280 next 74\n",
      "2024-02-28 15:30:11.703788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401a200 of size 768 next 79\n",
      "2024-02-28 15:30:11.703793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401a500 of size 1024 next 58\n",
      "2024-02-28 15:30:11.703799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401a900 of size 256 next 101\n",
      "2024-02-28 15:30:11.703804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401aa00 of size 512 next 77\n",
      "2024-02-28 15:30:11.703809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401ac00 of size 1024 next 51\n",
      "2024-02-28 15:30:11.703815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401b000 of size 768 next 84\n",
      "2024-02-28 15:30:11.703820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401b300 of size 512 next 91\n",
      "2024-02-28 15:30:11.703825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401b500 of size 256 next 99\n",
      "2024-02-28 15:30:11.703830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401b600 of size 256 next 100\n",
      "2024-02-28 15:30:11.703836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401b700 of size 256 next 98\n",
      "2024-02-28 15:30:11.703841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401b800 of size 256 next 95\n",
      "2024-02-28 15:30:11.703846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401b900 of size 256 next 47\n",
      "2024-02-28 15:30:11.703851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401ba00 of size 256 next 102\n",
      "2024-02-28 15:30:11.703857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 14619401bb00 of size 256 next 97\n",
      "2024-02-28 15:30:11.703862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619401bc00 of size 52224 next 49\n",
      "2024-02-28 15:30:11.703868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194028800 of size 35328 next 15\n",
      "2024-02-28 15:30:11.703873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194031200 of size 55296 next 67\n",
      "2024-02-28 15:30:11.703879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619403ea00 of size 256 next 105\n",
      "2024-02-28 15:30:11.703885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619403eb00 of size 256 next 107\n",
      "2024-02-28 15:30:11.703890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619403ec00 of size 1792 next 108\n",
      "2024-02-28 15:30:11.703895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619403f300 of size 12288 next 109\n",
      "2024-02-28 15:30:11.703901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194042300 of size 96000 next 25\n",
      "2024-02-28 15:30:11.703906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194059a00 of size 55296 next 19\n",
      "2024-02-28 15:30:11.703911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194067200 of size 331776 next 21\n",
      "2024-02-28 15:30:11.703917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1461940b8200 of size 110592 next 104\n",
      "2024-02-28 15:30:11.703922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1461940d3200 of size 331776 next 68\n",
      "2024-02-28 15:30:11.703928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146194124200 of size 110592 next 73\n",
      "2024-02-28 15:30:11.703933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619413f200 of size 110592 next 103\n",
      "2024-02-28 15:30:11.703938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619415a200 of size 442368 next 26\n",
      "2024-02-28 15:30:11.703944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1461941c6200 of size 1327104 next 28\n",
      "2024-02-28 15:30:11.703949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619430a200 of size 221184 next 110\n",
      "2024-02-28 15:30:11.703955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146194340200 of size 25878528 next 42\n",
      "2024-02-28 15:30:11.703960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146195bee200 of size 442368 next 76\n",
      "2024-02-28 15:30:11.703966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146195c5a200 of size 3538944 next 96\n",
      "2024-02-28 15:30:11.703971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146195fba200 of size 3096576 next 52\n",
      "2024-02-28 15:30:11.703976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 1461962ae200 of size 3538944 next 46\n",
      "2024-02-28 15:30:11.703982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619660e200 of size 1769472 next 81\n",
      "2024-02-28 15:30:11.703988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 1461967be200 of size 2654208 next 82\n",
      "2024-02-28 15:30:11.703993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146196a46200 of size 2654208 next 83\n",
      "2024-02-28 15:30:11.703999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146196cce200 of size 884736 next 71\n",
      "2024-02-28 15:30:11.704004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146196da6200 of size 442368 next 90\n",
      "2024-02-28 15:30:11.704015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146196e12200 of size 2654208 next 85\n",
      "2024-02-28 15:30:11.704021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619709a200 of size 3981312 next 86\n",
      "2024-02-28 15:30:11.704026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146197466200 of size 3981312 next 88\n",
      "2024-02-28 15:30:11.704031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 146197832200 of size 3981312 next 89\n",
      "2024-02-28 15:30:11.704037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146197bfe200 of size 3981312 next 80\n",
      "2024-02-28 15:30:11.704043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 146197fca200 of size 6635520 next 92\n",
      "2024-02-28 15:30:11.704048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619861e200 of size 28311552 next 106\n",
      "2024-02-28 15:30:11.704053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 14619a11e200 of size 28311552 next 56\n",
      "2024-02-28 15:30:11.704060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 14619bc1e200 of size 540417536 next 18446744073709551615\n",
      "2024-02-28 15:30:11.704065: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-02-28 15:30:11.704073: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 27 Chunks of size 256 totalling 6.8KiB\n",
      "2024-02-28 15:30:11.704080: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 512 totalling 1.5KiB\n",
      "2024-02-28 15:30:11.704086: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2024-02-28 15:30:11.704092: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1024 totalling 2.0KiB\n",
      "2024-02-28 15:30:11.704098: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2024-02-28 15:30:11.704104: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2024-02-28 15:30:11.704111: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12288 totalling 12.0KiB\n",
      "2024-02-28 15:30:11.704118: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 35328 totalling 34.5KiB\n",
      "2024-02-28 15:30:11.704125: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 52224 totalling 51.0KiB\n",
      "2024-02-28 15:30:11.704131: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 55296 totalling 54.0KiB\n",
      "2024-02-28 15:30:11.704137: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 110592 totalling 324.0KiB\n",
      "2024-02-28 15:30:11.704143: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 221184 totalling 216.0KiB\n",
      "2024-02-28 15:30:11.704150: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 442368 totalling 1.27MiB\n",
      "2024-02-28 15:30:11.704156: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 884736 totalling 864.0KiB\n",
      "2024-02-28 15:30:11.704162: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1769472 totalling 1.69MiB\n",
      "2024-02-28 15:30:11.704168: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 2654208 totalling 5.06MiB\n",
      "2024-02-28 15:30:11.704174: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3096576 totalling 2.95MiB\n",
      "2024-02-28 15:30:11.704192: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 3981312 totalling 11.39MiB\n",
      "2024-02-28 15:30:11.704199: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6635520 totalling 6.33MiB\n",
      "2024-02-28 15:30:11.704205: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 28311552 totalling 27.00MiB\n",
      "2024-02-28 15:30:11.704213: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 540417536 totalling 515.38MiB\n",
      "2024-02-28 15:30:11.704220: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 572.60MiB\n",
      "2024-02-28 15:30:11.704226: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 670564352 memory_limit_: 670564352 available bytes: 0 curr_region_allocation_bytes_: 1341128704\n",
      "2024-02-28 15:30:11.704236: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       670564352\n",
      "InUse:                       600419328\n",
      "MaxInUse:                    654611712\n",
      "NumAllocs:                         360\n",
      "MaxAllocSize:                540417536\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-02-28 15:30:11.704246: W tensorflow/tsl/framework/bfc_allocator.cc:497] *___************___********************************************************************xxxxxxxxxxxxx\n",
      "2024-02-28 15:30:11.704269: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at conv_ops_3d.cc:192 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1,16,192,192,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'unet/unet_enc_conv_0_1/Conv3D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/scratch/3798247/ipykernel_1111793/4147531862.py\", line 276, in <module>\n      hard_dice_score = calculate_hard_dice(crop_img, combined_model, mask)\n    File \"/scratch/3798247/ipykernel_1111793/4147531862.py\", line 199, in calculate_hard_dice\n      prediction_one_hot = process_image(image.data, model)\n    File \"/scratch/3798247/ipykernel_1111793/4147531862.py\", line 47, in process_image\n      return unet_model.predict(a[None,...,None], verbose=0)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2554, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2341, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2327, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2315, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2283, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'unet/unet_enc_conv_0_1/Conv3D'\nOOM when allocating tensor with shape[1,16,192,192,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node unet/unet_enc_conv_0_1/Conv3D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_4975]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 276\u001b[0m\n\u001b[1;32m    274\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mresize(new_voxsize)\u001b[38;5;241m.\u001b[39mreshape([dim_, dim_, dim_, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    275\u001b[0m mask\u001b[38;5;241m.\u001b[39mdata[mask\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 276\u001b[0m hard_dice_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_hard_dice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# prediction_one_hot = process_image(crop_data, combined_model)\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# print(np.unique(mask.data))\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# a = to_categorical(mask.data, num_classes=2)[None,...]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# last_10_soft_dice_scores.append(soft_dice_score)\u001b[39;00m\n\u001b[1;32m    286\u001b[0m mom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(folder\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[1], line 199\u001b[0m, in \u001b[0;36mcalculate_hard_dice\u001b[0;34m(image, model, mask_filename)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_hard_dice\u001b[39m(image, model, mask_filename):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# mask = sf.load_volume(mask_filename).reshape((dim_, dim_, dim_))\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     prediction_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     predictions_argmax \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction_one_hot, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    201\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(predictions_argmax, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 47\u001b[0m, in \u001b[0;36mprocess_image\u001b[0;34m(im, unet_model)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_image\u001b[39m(im, unet_model):\n\u001b[1;32m     46\u001b[0m     a \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'unet/unet_enc_conv_0_1/Conv3D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 701, in start\n      self.io_loop.start()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n      await self.process_one()\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n      await dispatch(*args)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n      await result\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n      reply_content = await reply_content\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/autofs/space/bal_004/users/jd1677/singularity-images/tensorflow_2.13.0-gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/scratch/3798247/ipykernel_1111793/4147531862.py\", line 276, in <module>\n      hard_dice_score = calculate_hard_dice(crop_img, combined_model, mask)\n    File \"/scratch/3798247/ipykernel_1111793/4147531862.py\", line 199, in calculate_hard_dice\n      prediction_one_hot = process_image(image.data, model)\n    File \"/scratch/3798247/ipykernel_1111793/4147531862.py\", line 47, in process_image\n      return unet_model.predict(a[None,...,None], verbose=0)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2554, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2341, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2327, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2315, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 2283, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'unet/unet_enc_conv_0_1/Conv3D'\nOOM when allocating tensor with shape[1,16,192,192,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node unet/unet_enc_conv_0_1/Conv3D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_4975]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from neurite.tf import models  # Assuming the module's location\n",
    "import voxelmorph.tf.losses as vtml\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import neurite as ne\n",
    "import sys\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.models import load_model\n",
    "from neurite_sandbox.tf.models import labels_to_labels\n",
    "import nibabel as nib\n",
    "import tqdm\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import neurite as ne\n",
    "import voxelmorph as vxm\n",
    "from utils import *\n",
    "import pathlib\n",
    "import surfa as sf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import surfa as sf\n",
    "from utils import resize\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def process_image(im, unet_model):\n",
    "    a = im.copy()\n",
    "    return unet_model.predict(a[None,...,None], verbose=0)\n",
    "    \n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2.0 * intersection) / (union) \n",
    "\n",
    "def my_hard_dice(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    dice = dice_coefficient(y_true_flat, y_pred_flat)\n",
    "    return dice\n",
    "\n",
    "def soft_dice(a, b):\n",
    "    dim = len(a.shape) - 2\n",
    "    space = list(range(1, dim + 1))\n",
    "    # print(\"dim\",dim,\"space\",space,\"a.dim\",a.shape,\"b.dim\",b.shape)\n",
    "    top = 2 * tf.reduce_sum(a * b, axis=space)\n",
    "    bot = tf.reduce_sum(a ** 2, axis=space) + tf.reduce_sum(b ** 2, axis=space)\n",
    "    \n",
    "    out = tf.divide(top, bot + 1e-6)\n",
    "    return -tf.reduce_mean(out)\n",
    "\n",
    "def my_dice_coefficient(y_true, y_pred, smooth=1e-8):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2.0 * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "def minmax_norm(x):\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "\n",
    "def find_manual_mask(filename):\n",
    "    base_filename, _ = os.path.splitext(filename)  # Separate filename and extension\n",
    "    pattern = re.compile(rf\"manual_masks_b\\d+_mom_\\d+_{re.escape(base_filename)}_segment\\.nii\\.gz\")\n",
    "\n",
    "    matches = [f for f in os.listdir(\"mgh_2d\") if pattern.match(f)]\n",
    "    \n",
    "    if matches:\n",
    "        return matches[0]\n",
    "        \n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "warp_blur_min=np.array([2, 4, 8])\n",
    "bias_blur_min=np.array([2, 4, 8])\n",
    "bias_blur_max=bias_blur_min*2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.seed(3000)\n",
    "\n",
    "def load_model3D(checkpoint_path,num_dim=3,nb_labels=2,\n",
    "                                            dimx=192,\n",
    "                                            dimy=192,\n",
    "                                            dimz=192,\n",
    "                                            batch_size=8,\n",
    "                                            warp_max=2.5,\n",
    "                                            warp_min=.5,\n",
    "                                            warp_blur_min=np.array([2, 4, 8]),\n",
    "                                            warp_blur_max=warp_blur_min*2,\n",
    "                                            bias_blur_min=np.array([2, 4, 8]),\n",
    "                                            bias_blur_max=bias_blur_min*2,\n",
    "                                            initial_lr=1e-4,\n",
    "                                            lr = 1e-4,\n",
    "                                            lr_lin = 1e-4,\n",
    "                                            nb_levels=5,\n",
    "                                            conv_size=3,\n",
    "                                            num_epochs=40000,\n",
    "                                            num_bg_labels=16,\n",
    "                                            nb_conv_per_level=2):\n",
    "    input_img = Input(shape=(dimx, dimy, dimz, 1))\n",
    "    \n",
    "    unet_model = vxm.networks.Unet(inshape=(dimx, dimy, dimz, 1), nb_features=(en, de), \n",
    "                                   nb_conv_per_level=nb_conv_per_level,\n",
    "                                   final_activation_function='softmax')\n",
    "\n",
    "    segmentation = unet_model(input_img)\n",
    "    combined_model = Model(inputs=input_img, outputs=segmentation)\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        combined_model.load_weights(checkpoint_path)\n",
    "        print(\"Loaded weights from the checkpoint and continued training.\")\n",
    "    else:\n",
    "        # print(checkpoint_path)\n",
    "        print(\"Checkpoint file not found.\")\n",
    "    unet_model = combined_model.layers[-1]\n",
    "\n",
    "    return unet_model\n",
    "\n",
    "\n",
    "num_row = 3\n",
    "per_row = 10\n",
    "\n",
    "    \n",
    "def calculate_dice_coefficient(ground_truth, predicted):\n",
    "    intersection = np.sum(np.logical_and(ground_truth, predicted))\n",
    "    union = np.sum(np.logical_or(ground_truth, predicted))\n",
    "\n",
    "    dice_coefficient = (2.0 * intersection) / (union + intersection)\n",
    "    return dice_coefficient\n",
    "\n",
    "def print_row_dice_coefficients(i, row_dice_coefficients):\n",
    "    formatted_dice = [f\"   {dice:.4f}\" for j, dice in enumerate(row_dice_coefficients)]\n",
    "    num_spaces = num_row-1\n",
    "    padding_left = 0\n",
    "    padding_right = 0\n",
    "\n",
    "    formatted_output = f\"{' ' * padding_left}{'       '.join(formatted_dice)}{' ' * padding_right}\"\n",
    "    print(f' {formatted_output}')\n",
    "    \n",
    "\n",
    "# log_dir='logs_feta'\n",
    "# initial_epoch=5870\n",
    "\n",
    "import os, shutil, glob\n",
    "\n",
    "# models_dir='models_mgh_brain_mgh_body_192'\n",
    "# models_dir='models_feta_mgh_body_192'\n",
    "# models_dir = 'models_feta_mgh_brain_mgh_body_192'\n",
    "# models_dir='models_synth_shapes_feta_192'\n",
    "# models_dir='models_synth_feta_mgh_brain_mgh_body_192'\n",
    "models_dir='models_shapes_feta_192'\n",
    "\n",
    "# latest_weight = max(glob.glob(os.path.join(models_dir, 'weights_epoch_*.h5')), key=os.path.getctime, default=None)\n",
    "# match = re.search(r'weights_epoch_(\\d+)\\.h5', latest_weight)\n",
    "# latest_epoch = int(match.group(1))\n",
    "\n",
    "en=[16,16, 32,32, 64,64,128,128, 192,192]\n",
    "de=[192,192, 128,128,64,64,32,32,16,16,2]\n",
    "\n",
    "# en = [16, 16, 32 ,32 ,64 ,64 ,64 ,64 ,64 ,64 ,64 ,64 ,64]\n",
    "# de = [64 ,64 ,64 ,64, 64 ,64 ,64, 64, 64, 32 ,32 ,16 ,16 ,2]\n",
    "\n",
    "nb_features = '_'.join(map(str, en))\n",
    "dim_=192\n",
    "\n",
    "\n",
    "# models_dir='models_feta_mgh_body_params_dim_256_16_16_32_32_64_64_128_128_256_256_wm_0.2_shift_30'\n",
    "# checkpoint_path=models_dir+latest_weight#'/weights_epoch_'+str(initial_epoch)+'.h5'\n",
    "# print(checkpoint_path)\n",
    "# combined_model = load_model3D(checkpoint_path,num_dim=3, dimx=dim_,\n",
    "#                                                        dimy=dim_,\n",
    "#                                                        dimz=dim_)\n",
    "\n",
    "# dataset=\"samples\"\n",
    "def calculate_hard_dice(image, model, mask_filename):\n",
    "    # mask = sf.load_volume(mask_filename).reshape((dim_, dim_, dim_))\n",
    "\n",
    "\n",
    "    prediction_one_hot = process_image(image.data, model)\n",
    "    predictions_argmax = np.argmax(prediction_one_hot, axis=-1)\n",
    "    prediction = np.squeeze(predictions_argmax, axis=0)\n",
    "    mask.data[mask.data != 0] = 1\n",
    "    return my_hard_dice(prediction.flatten(),mask.data.flatten())\n",
    "\n",
    "last_models_hard_dice_scores = []\n",
    "n = 500\n",
    "# for i in range(latest_epoch, latest_epoch - n, -10):\n",
    "latest_weight = max(glob.glob(os.path.join(models_dir, 'weights_epoch_*.h5')), key=os.path.getctime, default=None)\n",
    "\n",
    "match = re.search(r'(\\d+)', latest_weight.split(\"/\")[1])\n",
    "initial_epoch = int(match.group())\n",
    "# print(initial_epoch)\n",
    "# checkpoint_path=models_dir+'/weights_epoch_'+str(initial_epoch)+'.h5'\n",
    "# combined_model = load_model3D(checkpoint_path,num_dim=3, dimx=dim_,\n",
    "#                                                        dimy=dim_,\n",
    "#                                                        dimz=dim_)\n",
    "checkpoint_path=models_dir+'/weights_epoch_'+str(initial_epoch)+'.h5'\n",
    "print(checkpoint_path)\n",
    "combined_model = load_model3D(checkpoint_path,num_dim=3, dimx=dim_,\n",
    "                                                       dimy=dim_,\n",
    "                                                       dimz=dim_)\n",
    "# combined_model.summary()\n",
    "\n",
    "validation_folder_path=\"validation\"\n",
    "subfolders = [f.name for f in os.scandir(validation_folder_path) if f.is_dir()]\n",
    "def visualize(combined_model,image,mask):\n",
    "    crop_img = image.resize([1.5, 1.5, 1.5]).reshape((dim_, dim_, dim_,1))    \n",
    "    crop_data = minmax_norm(crop_img.data)\n",
    "    \n",
    "    prediction_one_hot = process_image(crop_data, combined_model)\n",
    "    predictions_argmax = np.argmax(prediction_one_hot, axis=-1)\n",
    "    prediction = np.squeeze(predictions_argmax, axis=0)\n",
    "\n",
    "    prediction = sf.Volume(prediction)#.reshape(mask.data.shape)#.resample_like(mask)\n",
    "    # mask.data[mask.data != 0] = 1\n",
    "    hard_dice_score = my_hard_dice(mask.data, prediction.data)\n",
    "    \n",
    "    print(f\"Hard Dice Coefficient: {hard_dice_score}\")\n",
    "    \n",
    "    ne.plot.volume3D(crop_img);\n",
    "    ne.plot.volume3D(mask);\n",
    "    ne.plot.volume3D(prediction);\n",
    "\n",
    "\n",
    "new_voxsize = [1.5,1.5,1.5]\n",
    "\n",
    "b2_hard_dice_scores=[]\n",
    "b3_hard_dice_scores=[]\n",
    "# last_soft_dice_scores=[]\n",
    "latest_images=[]\n",
    "latest_masks=[]\n",
    "step_size=40\n",
    "for w in range(0, initial_epoch+1, step_size):\n",
    "    checkpoint_path=models_dir+'/weights_epoch_'+str(w)+'.h5'\n",
    "    combined_model = load_model3D(checkpoint_path,num_dim=3, dimx=dim_,\n",
    "                                                           dimy=dim_,\n",
    "                                                           dimz=dim_)\n",
    "\n",
    "    b2_10_hard_dice_scores = []\n",
    "    b3_10_hard_dice_scores = []\n",
    "    # last_10_soft_dice_scores =[]\n",
    "    for folder in subfolders:\n",
    "        folder_path = os.path.join(validation_folder_path, folder)\n",
    "        filename = os.path.join(folder_path,\"image.nii.gz\")\n",
    "        mask_filename = os.path.join(folder_path,\"manual.nii.gz\")\n",
    "        image = sf.load_volume(filename)\n",
    "        orig_voxsize = image.geom.voxsize\n",
    "        crop_img = image.resize([orig_voxsize[0],orig_voxsize[1],1.5], method=\"nearest\")\n",
    "        crop_img = crop_img.resize(new_voxsize, method=\"linear\").reshape([dim_, dim_, dim_])\n",
    "        crop_data = minmax_norm(crop_img.data)\n",
    "    \n",
    "        mask = sf.load_volume(mask_filename).resize([orig_voxsize[0],orig_voxsize[1],1\n",
    "                                                    ], method=\"nearest\")\n",
    "        mask = mask.resize(new_voxsize).reshape([dim_, dim_, dim_, 1])\n",
    "        mask.data[mask.data != 0] = 1\n",
    "        hard_dice_score = calculate_hard_dice(crop_img, combined_model, mask)\n",
    "\n",
    "        # prediction_one_hot = process_image(crop_data, combined_model)\n",
    "        # print(np.unique(mask.data))\n",
    "        # a = to_categorical(mask.data, num_classes=2)[None,...]\n",
    "        # b=prediction_one_hot\n",
    "        # soft_dice_score = soft_dice(a, b)\n",
    "        # hard_dice_score = my_hard_dice(mask.data, prediction.data)\n",
    "                \n",
    "        # last_10_soft_dice_scores.append(soft_dice_score)\n",
    "        mom = int(folder.split(\"_\")[1])\n",
    "        # print(folder)\n",
    "        if mom < 100:\n",
    "            b2_10_hard_dice_scores.append(hard_dice_score)\n",
    "        else:\n",
    "            b3_10_hard_dice_scores.append(hard_dice_score)\n",
    "        if abs(w-initial_epoch)<step_size:\n",
    "            print(w)\n",
    "            latest_images.append(crop_img)\n",
    "            latest_masks.append(mask)\n",
    "    b2_hard_dice_scores.append(np.mean(b2_10_hard_dice_scores))\n",
    "    b3_hard_dice_scores.append(np.mean(b3_10_hard_dice_scores))\n",
    "    # last_soft_dice_scores.append(np.mean(last_10_soft_dice_scores))\n",
    "\n",
    "        # visualize(image,mask)\n",
    "for i in range(len(latest_images)):\n",
    "    visualize(combined_model, latest_images[i],latest_masks[i])\n",
    "# last_hard_dice_scores.reverse()\n",
    "plt.bar(range(len(b3_hard_dice_scores)), b3_hard_dice_scores, color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('B3 Hard Dice Score')\n",
    "plt.title('Mean Hard Dice')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.bar(range(len(b2_hard_dice_scores)), b2_hard_dice_scores, color='red')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('B2 Hard Dice Score')\n",
    "plt.title('Mean Hard Dice')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "    # files = os.listdir(folder_path)\n",
    "    # for f in files:\n",
    "        # print(f\"Files in the folder: {f}\")\n",
    "        \n",
    "# for j in range(10):\n",
    "#     filename = f'feta_shapes_{j}.nii.gz'\n",
    "#     mask_filename = f'feta_mask_shapes{j}.nii.gz'\n",
    "\n",
    "#     image = sf.load_volume(os.path.join(dataset, filename))\n",
    "#     hard_dice_score = calculate_hard_dice(image, combined_model, mask_filename)\n",
    "#     last_10_hard_dice_scores.append(hard_dice_score)\n",
    "# last_models_hard_dice_scores.append(np.mean(last_10_hard_dice_scores))\n",
    "    # filename=\"feta_shapes_0.nii.gz\"\n",
    "    # manual_mask='feta_mask_shapes0.nii.gz'\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# image = sf.load_volume(os.path.join(dataset, filename))#.resize()\n",
    "# print(image.shape,image.geom.voxsize)\n",
    "# # dim_ = 192\n",
    "\n",
    "# crop_img = image.resize([1, 1, 1]).reshape((dim_, dim_, dim_,1))\n",
    "# # crop_img.save(\"output/crop_img.mgz\")\n",
    "\n",
    "# crop_data = minmax_norm(crop_img.data)\n",
    "\n",
    "# prediction_one_hot = process_image(crop_data, combined_model)\n",
    "# predictions_argmax = np.argmax(prediction_one_hot, axis=-1)\n",
    "# prediction = np.squeeze(predictions_argmax, axis=0)\n",
    "\n",
    "########### visualize ########\n",
    "\n",
    "# mask = sf.load_volume(os.path.join(dataset, manual_mask)).reshape((dim_, dim_, dim_))\n",
    "# prediction = sf.Volume(prediction)#.reshape(mask.data.shape)#.resample_like(mask)\n",
    "\n",
    "# output_file_path = os.path.join('output', 'prediction.nii.gz')\n",
    "# save_prediction(crop_img, prediction, output_file_path)\n",
    "\n",
    "# a = to_categorical(mask.data, num_classes=2)[None,...]\n",
    "# b=prediction_one_hot\n",
    "# dice_score = soft_dice(a, b)\n",
    "# hard_dice_score = my_hard_dice(mask.data, prediction.data)\n",
    "\n",
    "# Average the last 10 hard dice scores\n",
    "# average_hard_dice = np.mean(last_10_hard_dice_scores)\n",
    "\n",
    "# Plot the results for the last 20 models\n",
    "# k = len(last_models_hard_dice_scores)\n",
    "# plt.plot(range(initial_epoch, initial_epoch - 10*k, -10), last_models_hard_dice_scores[-k:][::-1], marker='o')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Hard Dice Score')\n",
    "# # plt.title(f'Last 20 Models Hard Dice Scores (Average: {last_models_hard_dice_scores:.4f})')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d16e5a1c-ed37-4158-bb49-04f06af019ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_weight = max(glob.glob(os.path.join(models_dir, 'weights_epoch_*.h5')), key=os.path.getctime, default=None)\n",
    "match = re.search(r'weights_epoch_(\\d+)\\.h5', latest_weight)\n",
    "latest_epoch = int(match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8ef859-3685-499a-aaf3-2f01b9d37d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001\n"
     ]
    }
   ],
   "source": [
    "print(np.max(mask.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eabb022-ef21-43a6-82bc-7731f3a64f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5625, 1.5625, 4.    ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.geom.voxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20932e01-b30a-407f-a614-023bed2a487d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493fa9d-4de0-47b4-82a5-47cdbaf381df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
